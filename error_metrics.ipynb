{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a655a03c-0484-4d7c-869b-4af9d03a5d69",
   "metadata": {},
   "source": [
    "## Checking the accuracy of the models: Random Forest vs. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a7a15-d7f4-4042-8ffd-9cf3b9cb4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416a862e-c0fe-4f63-94b8-bdd5edf25e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for lightGBM algorithm: 0.4254033992432911\n"
     ]
    }
   ],
   "source": [
    "# training dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# calculate molecular descriptors\n",
    "def calculate_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    descriptors = {}\n",
    "    descriptors['MolWt'] = Descriptors.MolWt(mol)\n",
    "    descriptors['MolLogP'] = Descriptors.MolLogP(mol)\n",
    "    descriptors['TPSA'] = Descriptors.TPSA(mol)\n",
    "    descriptors['NumHDonors'] = Descriptors.NumHDonors(mol)\n",
    "    descriptors['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)\n",
    "    descriptors['NumRotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "    return descriptors\n",
    "\n",
    "# Calculate descriptors for molecules in the training dataset\n",
    "descriptor_list = []\n",
    "for index, row in dataset.iterrows():\n",
    "    descriptors = calculate_descriptors(row['NAME'])\n",
    "    if descriptors is not None:\n",
    "        descriptor_list.append(descriptors)\n",
    "\n",
    "# Convert descriptor data into DataFrame\n",
    "descriptor_df = pd.DataFrame(descriptor_list)\n",
    "\n",
    "# target logBB values\n",
    "target_list = dataset['logBB']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(descriptor_df, target_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# model lightGBM\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of logBB values for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error for lightGBM algorithm:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef4c96ad-77e6-4e00-a95f-8026bc78cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for random forest algorithm: 0.40871410937508934\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your training dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Calculate molecular descriptors\n",
    "def calculate_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    descriptors = {}\n",
    "    descriptors['MolWt'] = Descriptors.MolWt(mol)\n",
    "    descriptors['MolLogP'] = Descriptors.MolLogP(mol)\n",
    "    descriptors['TPSA'] = Descriptors.TPSA(mol)\n",
    "    descriptors['NumHDonors'] = Descriptors.NumHDonors(mol)\n",
    "    descriptors['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)\n",
    "    descriptors['NumRotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "    return descriptors\n",
    "\n",
    "# Calculate descriptors for molecules in the training dataset\n",
    "descriptor_list = []\n",
    "for index, row in dataset.iterrows():\n",
    "    descriptors = calculate_descriptors(row['NAME'])\n",
    "    if descriptors is not None:\n",
    "        descriptor_list.append(descriptors)\n",
    "\n",
    "# Convert descriptor data into DataFrame\n",
    "descriptor_df = pd.DataFrame(descriptor_list)\n",
    "\n",
    "# target logBB values\n",
    "target_list = dataset['logBB']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(descriptor_df, target_list, test_size=0.2, random_state=42)\n",
    "\n",
    "#model random forest\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict logBB values for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error for random forest algorithm:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2a1f4-7be8-4146-aa5c-edbb187b883a",
   "metadata": {},
   "source": [
    "### MSE measures the average squared differences between the actual and predicted values. Therefore the lower the better. So, for the prediction of LogBB of the Zinc20 dataset the random forest algoritm, with the MSE value 0,40, is used. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
